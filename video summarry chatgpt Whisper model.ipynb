{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f96c2355",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import librosa\n",
    "import openai\n",
    "import soundfile as sf\n",
    "\n",
    "# Set the OpenAI API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\" # Add your openai here\n",
    "\n",
    "# Check if the OpenAI API key is set\n",
    "assert os.getenv(\"OPENAI_API_KEY\") is not None, \"\" # Add your openai here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e88daff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_audio_files(path, extension=\".mp3\"):\n",
    "    \"\"\"Recursively find all files with extension in path.\"\"\"\n",
    "    audio_files = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        for f in files:\n",
    "            if f.endswith(extension):\n",
    "                audio_files.append(os.path.join(root, f))\n",
    "\n",
    "    return audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35d8fcc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd0b2706",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_audio(filename, segment_length: int, output_dir):\n",
    "    \"\"\"segment length is in seconds\"\"\"\n",
    "\n",
    "    print(f\"Chunking audio to {segment_length} second segments...\")\n",
    "\n",
    "    if not os.path.isdir(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "\n",
    "    # load audio file\n",
    "    audio, sr = librosa.load(filename, sr=44100)\n",
    "\n",
    "    # calculate duration in seconds\n",
    "    duration = librosa.get_duration(y=audio, sr=sr)\n",
    "\n",
    "    # calculate number of segments\n",
    "    num_segments = int(duration / segment_length) + 1\n",
    "\n",
    "    print(f\"Chunking {num_segments} chunks...\")\n",
    "\n",
    "    # iterate through segments and save them\n",
    "    for i in range(num_segments):\n",
    "        start = i * segment_length * sr\n",
    "        end = (i + 1) * segment_length * sr\n",
    "        segment = audio[start:end]\n",
    "        sf.write(os.path.join(output_dir, f\"segment_{i}.mp3\"), segment, sr)\n",
    "\n",
    "    chunked_audio_files = find_audio_files(output_dir)\n",
    "    return sorted(chunked_audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf6ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe_audio(audio_files: list, output_file=None, model=\"whisper-1\") -> list:\n",
    "\n",
    "    print(\"Converting audio to text...\")\n",
    "\n",
    "    transcripts = []\n",
    "    for audio_file in audio_files:\n",
    "        audio = open(audio_file, \"rb\")\n",
    "        response = openai.Audio.transcribe(model, audio)\n",
    "        transcripts.append(response[\"text\"])\n",
    "\n",
    "    if output_file is not None:\n",
    "        # save all transcripts to a .txt file\n",
    "        with open(output_file, \"w\") as file:\n",
    "            for transcript in transcripts:\n",
    "                file.write(transcript + \"\\n\")\n",
    "\n",
    "    return transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e1e4362",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(chunks: list[str], system_prompt: str, model=\"gpt-3.5-turbo\", output_file=None):\n",
    "    print(f\"Summarizing with {model=}\")\n",
    "\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": chunk},\n",
    "            ],\n",
    "        )\n",
    "        summary = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        summaries.append(summary)\n",
    "\n",
    "    if output_file is not None:\n",
    "        # save all transcripts to a .txt \\file\n",
    "        with open(output_file, \"w\") as file:\n",
    "            for summary in summaries:\n",
    "                file.write(summary + \"\\n\")\n",
    "\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93add5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"  # Add your openai here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d53b648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Set the API key explicitly\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92444393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the OpenAI API key as an environment variable\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"   # Add your openai here\n",
    "\n",
    "# Set the API key explicitly\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9d46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_local_video(video_file, output_dir):\n",
    "    raw_audio_dir = f\"{outputs_dir}/raw_audio/\"\n",
    "    chunks_dir = f\"{outputs_dir}/chunks\"\n",
    "    transcripts_file = f\"{outputs_dir}/transcripts.txt\"\n",
    "    summary_file = f\"{outputs_dir}/summary.txt\"\n",
    "    segment_length = 10 * 60  # chunk to 10 minute segments\n",
    "\n",
    "    if os.path.exists(outputs_dir):\n",
    "        # delete the outputs_dir folder and start from scratch\n",
    "        shutil.rmtree(outputs_dir)\n",
    "        os.mkdir(outputs_dir)\n",
    "\n",
    "    # chunk the video's audio to shorter audio files\n",
    "    chunked_audio_files = chunk_audio(video_file, segment_length=segment_length, output_dir=chunks_dir)\n",
    "\n",
    "    # transcribe each chunked audio file\n",
    "    transcriptions = transcribe_audio(chunked_audio_files, transcripts_file)\n",
    "\n",
    "    # summarize each transcription\n",
    "    system_prompt_tldr = \"\"\"\n",
    "    You are a helpful assistant that summarizes local videos.\n",
    "    Someone has already summarized the video to key points.\n",
    "    Summarize the key points to one or two sentences that capture the essence of the video.\n",
    "    \"\"\"\n",
    "    # put the entire summary to a single entry\n",
    "    long_summary = \"\\n\".join(transcriptions)\n",
    "    short_summary = summarize([long_summary], system_prompt=system_prompt_tldr, output_file=summary_file)[0]\n",
    "\n",
    "    return short_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0aad9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking audio to 600 second segments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_13820\\1732844154.py:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(filename, sr=44100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking 1 chunks...\n",
      "Converting audio to text...\n",
      "Summarizing with model='gpt-3.5-turbo'\n",
      "Video - TL;DR\n",
      "================================================================================\n",
      "The key points in the video include the importance of choosing a niche that you're passionate about in video editing, selecting a top editing software like Adobe Premiere Pro, learning through project-oriented practice to quickly master editing skills, developing a diverse skill set to add value as a video editor, studying successful creators to improve your editing style, pricing your work based on the value you provide, and maintaining a positive mindset for continual learning and growth in the field to achieve success as a video editor.\n"
     ]
    }
   ],
   "source": [
    "video_file_path = r\"C:\\Users\\Hp\\Desktop\\Fyp Modules\\Module 1 Python trim\\final video trimmer\\test_ALTERED.mp4\"\n",
    "outputs_dir = \"outputs/\"\n",
    "\n",
    "short_summary = summarize_local_video(video_file_path, outputs_dir)\n",
    "\n",
    "print(\"Video - TL;DR\")\n",
    "print(\"=\" * 80)\n",
    "print(short_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4bdb45fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking audio to 600 second segments...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_13820\\1732844154.py:10: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sr = librosa.load(filename, sr=44100)\n",
      "C:\\Users\\Hp\\anaconda3\\Lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunking 1 chunks...\n",
      "Converting audio to text...\n",
      "Summarizing with model='gpt-3.5-turbo'\n",
      "Video - TL;DR\n",
      "================================================================================\n",
      "The Interreg Podcast highlights the stories of individuals and communities across Europe who cooperate across borders to build a better and more sustainable future through projects funded by the European Union. Through showcasing diverse initiatives from nurturing children in border areas to creating greener cities, the podcast aims to convey the value of cooperation and collaboration in shaping a positive future for Europe.\n"
     ]
    }
   ],
   "source": [
    "video_file_path = r\"C:\\Users\\Hp\\Desktop\\Fyp Modules\\Module 1 Python trim\\final video trimmer\\demo2.mp4\"\n",
    "outputs_dir = \"outputs/\"\n",
    "\n",
    "short_summary = summarize_local_video(video_file_path, outputs_dir)\n",
    "\n",
    "print(\"Video - TL;DR\")\n",
    "print(\"=\" * 80)\n",
    "print(short_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f3af54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
